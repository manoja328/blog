{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":"<p>This blog was published with MkDocs.</p>"},{"location":"#hello-world","title":"Hello World!","text":"<p>\u201cWe are just an advanced breed of monkeys on a minor planet of a very average star. But we can understand the Universe. That makes us something very special.\u201d \u2013 Stephen Hawking </p>"},{"location":"Features/LaTeX%20Math%20Support/","title":"LaTeX Math Support","text":"<p>LaTeX math is supported using MathJax.</p> <p>Inline math looks like \\(f(x) = x^2\\). The input for this is <code>$f(x) = x^2$</code>. Use <code>$...$</code>.</p> <p>For a block of math, use <code>$$...$$</code> on separate lines</p> <pre><code>$$\nF(x) = \\int^a_b \\frac{1}{2}x^4\n$$\n</code></pre> <p>gives </p> \\[ F(x) = \\int^a_b \\frac{1}{2}x^4 \\]"},{"location":"Features/Mermaid%20Diagrams/","title":"Mermaid diagrams","text":"<p>Here's the example from MkDocs Material documentation: </p> <pre><code>graph LR\n  A[Start] --&gt; B{Error?};\n  B --&gt;|Yes| C[Hmm...];\n  C --&gt; D[Debug];\n  D --&gt; B;\n  B ----&gt;|No| E[Yay!];</code></pre>"},{"location":"Features/Text%20Formatting/","title":"Text Formatting","text":"<p>You can have lists like this</p> <ul> <li>first</li> <li>second</li> <li>third</li> </ul> <p>Or checklist lists to</p> <ul> <li> Get</li> <li> things</li> <li> done</li> </ul> <p>Also, get highlights and strikethroughs as above (similar to Obsidian).</p> <p>More formatting options for your webpage here. (but not compatible with Obsidian)</p>"},{"location":"content/ball%20and%20beam/","title":"Ball and Beam System","text":"<p>The \"Ball on Beam\" project is a PID-controlled system designed to achieve precise control and balance of a ball moving along a linear beam. Previous methods use   potentiometer to set the  desired position. Instead, we use hand gesture to set the ball's position on the beam.  We use simple image processing techniques such as HSV thresholding to isolate the ball and OpenCV's  \"moments\" to calculate the center of the ball. Similarly, we use Hough Transform to compute the setpoint from the hand pose.</p> <p></p> <p></p> <p>My setup had following things:   1. A laptop with webcam   2. A PIC microcontroller (PIC16f877A)   3. A USB to Serial module   4. A home-made ball and beam setup attached to a Servo motor</p> <p>I implemented  the control logic using a Python script, which can be found at the end of this post. The purpose of the algorithm is to control the movement of a tennis ball along a beam. which is a low-cost wire cover with a groove that allows the ball to move in a straight path. The beam is attached to a fixed support and is manipulated by a servo motor. The servo motor is controlled by a PIC microcontroller, and the extent of movement is communicated from my laptop to the PIC via a USB-Serial module.</p> <p>The data sent from the laptop to the PIC microcontroller is the desired angle at which the servo motor should move. This angle is calculated based on the position of the ball and the desired setpoint. To achieve precise control over the system, a proportional-integral-derivative (PID) control algorithm is employed. The PID controller provides feedback to the entire system, allowing for adjustments and corrections in real-time.</p> <p>In summary, the Python script on my laptop calculates the desired angle for the servo motor based on the ball's position and setpoint. This information is then transmitted to the PIC microcontroller via a USB-Serial module, which converts it into an appropriate electrical signal to drive the servo motor. The PID control algorithm ensures accurate control and feedback for the system. If you would like to see the specific details of the Python script, please refer to the code and the video provided below.</p> <p>Video link</p> <p>Code</p>","tags":["embedded","image_processing"]},{"location":"content/debug%20ML%20systems/","title":"Helpful tips to debug ML systems","text":"<ol> <li>Always check your data<ul> <li>Visualize outputs/labels  and the  inputs</li> <li>Visualize the data distribution and try to find patterns</li> <li>May also try if simple methods like  Kernel SVM , Random Forest work reasonably. If not then some problem with the dataset</li> <li>Duplicated examples , bad data , corrupted labels</li> <li>Do you need to do Data processing ?<ul> <li>Mean centering , Whitening etc.</li> </ul> </li> <li>Look for dataset imbalance and biases<ul> <li>Up-sample or Down-sample if you see imbalance</li> </ul> </li> </ul> </li> <li>Start by overfitting on few samples by turning the regularization off. If the loss doesnot converge to zero then there  might be a problem.</li> <li>Start with simple model then gradually increase model complexity.</li> <li>Is the model underfitting or overfitting?  Simple checks can be done using k-Fold cross validation and seeing train and val losses. Run on small version or mini-validation data especially if you are running huge datasets. Use Tensorboard, weight&amp;biases or other solutions to visualize the  losses.<ul> <li>Underfitting: both train and test errors are high.</li> <li>Solutions:<ul> <li>Increase model complexity</li> </ul> </li> <li>Overfitting: train error low but test error high.</li> <li>Solutions:<ul> <li>Collect more data</li> <li>Decrease model complexity eg. fewer units, reduce no. of  hidden layers</li> <li>Regularize:<ul> <li>Dropout </li> <li>Batchnorm </li> <li>Early stopping </li> <li>L2 weight decay</li> <li>Ensemble</li> </ul> </li> </ul> </li> </ul> </li> <li>See that scales of losses are OK</li> <li>check for anomaly in gradient values<ul> <li>If you find that gradient are blowing-up then you can perform gradient clipping.</li> </ul> </li> <li>check if there are <code>NaNs</code>or <code>Infs</code> or really weird values. Below, I describe a scenario that I faced.<ul> <li>e.g. I was getting  NaNs  while running a Faster-RCNN model. I checked all the losses and found that my loss for classification was fine. But, I was getting NaNs just for co-ordinate regressors. Upon digging deep I found that  something like below could be happening:</li> </ul> </li> </ol> <pre><code>1. (x,y) of bounding boxes &gt; H / W of the image. \n2. xmin = xmax or ymin = ymax\n3. Small sized bounding boxes\n\nEasy fixes could be something like not loading small boxes i.e ensuring |xmax -xmin| &gt;= 10 in your dataloader. \n</code></pre> <p>Code to display warning if NaNs found in loss in pytorch: <pre><code>loss =  ##\nif torch.isnan(loss):\n   print (\"nans encountered\", ids)\n   import ipdb; ipdb.set_trace()\n</code></pre></p> <p>Additionally to debug during  the backward pass you will need to add few hooks and print statements.</p> <pre><code>class MyModel(nn.Module):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        self.model = models.resnet18(pretrained = True)\n        self.gradients = []\n        ## your layers\n        self.model.avgpool.register_backward_hook(self.save_gradients)\n\n    def forward(self, x):\n        ## your forward pass\n        return self.model(x)\n\n    def save_gradients(self, module, grad_input, grad_output):\n        name = module._get_name()\n        self.gradients.append(grad_output)\n\nmodel = MyModel()\nx = torch.rand(1,3,224,224)\noutput = model(x)\noutput.backward()\nprint(model.gradients)\n</code></pre> <ol> <li> <p>Code Sanity checks </p> <ul> <li>Check the conditional logic if/then/else in your code  and be sure they are really doing intended things</li> <li>Deliver clear error/warning messages <ul> <li>eg. I made a silly mistake where I didnot initilialize a model if the checkpoint is not found. I forgot to add an error message to show the  folder not found  error. So, I was unaware if the model is being initialized or not.</li> </ul> </li> <li>Have asserts in dataloader to prevent  absolutely ridiculous things from happening<ul> <li>E.g. check if bounding box min and max are the same or if  box coordinates are larger than the  image</li> </ul> </li> </ul> </li> <li> <p>Learn how to use a debugger.  ipdb or pdb  for python to trace the points where you keep getting errors. Its better than using print debugging since you can examine each steps. Also, It might come handy to learn some pdb commands.</p> </li> </ol>","tags":["ML"]},{"location":"content/debug%20ML%20systems/#resources","title":"Resources","text":"<ol> <li>37 Reasons why your Neural Network is not working</li> <li>A Recipe for Training Neural Networks</li> <li>Debugging Neural Networks Checklist</li> <li>How to Debug Neural Networks (Manual)</li> <li>4 Ways to Debug Your Deep Neural Network</li> <li>Debugging Neural Networks: A Checklist</li> <li>CNN Tricks</li> <li>Debug a Deep Learning Network - Part 5</li> </ol>","tags":["ML"]},{"location":"papers/ADAPTING%20LARGE%20LANGUAGE%20MODELS%20VIA%20READING%20COMPREHENSION/","title":"ADAPTING LARGE LANGUAGE MODELS VIA READING COMPREHENSION","text":"","tags":["ML","paper"]},{"location":"papers/ADAPTING%20LARGE%20LANGUAGE%20MODELS%20VIA%20READING%20COMPREHENSION/#takeaways","title":"Takeaways","text":"<ul> <li>talks about how to adapt LLMs through transformation of raw corpora to series of NLP tasks</li> <li>much better than just feeding raw texts </li> <li>Just fine-tuning causes a drop in its prompting ability ?? ( Table 1 ) .. not very conclusive of this experiment personally</li> <li>Related to instruction fine-tuning and create IFT data .. older method use more capable LLMs to create such examples ( but has a high cost)</li> </ul>","tags":["ML","paper"]},{"location":"papers/ADAPTING%20LARGE%20LANGUAGE%20MODELS%20VIA%20READING%20COMPREHENSION/#example","title":"Example","text":"<p>Here is the first part of an article about biomedicine: Recent reported evidence indicates that vocal cord carcinoma is evolving similarly to oropharyngeal cancer with an increasing number of patients (...) </p> <ul> <li> <p>Answer questions based on the article: What is a summary? Glottic Carcinoma in Young Patients.</p> </li> <li> <p>Generate a sentence that includes these biomedicine keywords [carcinoma, oropharyngeal, papillomavirus]: Recent reported evidence indicates that vocal cord carcinoma is evolving...</p> </li> <li> <p>Premise:... Hypothesis:... Does the premise entail the hypothesis? Yes What is the reason for \u201d...\"? the morphology of the lesions and the patients' young age.</p> </li> <li> <p>Compose a sentence that contradicts the meaning of \"Historically, glottic carcinoma ... \u201d.  </p> </li> <li> <p>Answer: Recent published evidence ...</p> </li> <li> <p>How would you complete the article? This finding further supports...</p> </li> </ul>","tags":["ML","paper"]},{"location":"papers/ADAPTING%20LARGE%20LANGUAGE%20MODELS%20VIA%20READING%20COMPREHENSION/#hows","title":"Hows","text":"<ul> <li>Use templates to create such task <ul> <li>To identify domain-specific words, they  use the SentencePiece tool (Kudo &amp; Richardson, 2018) to build a vocabulary from the target domain corpora.</li> <li>Then use the domain-specific keywords in the sentence as the input, asking the model to generate a sentence with</li> <li>Generate a sentence that includes these {DOMAIN} keywords.</li> </ul> </li> <li>For  \u201cEntailment\u201d if they are connected by the verbalizer Therefore, and as \u201cContradictory\u201d if connected by However.</li> </ul>","tags":["ML","paper"]},{"location":"papers/ADAPTING%20LARGE%20LANGUAGE%20MODELS%20VIA%20READING%20COMPREHENSION/#data","title":"Data","text":"<ul> <li>financial news from May 2022 to May 20232 for over 7, 000 stocks, using the FinGPT codebase</li> <li>PubMed Abstracts and FreeLaw Opinions from the Pile as pre-training corpora for the biomedicine and law domains</li> </ul>","tags":["ML","paper"]},{"location":"papers/ADAPTING%20LARGE%20LANGUAGE%20MODELS%20VIA%20READING%20COMPREHENSION/#models","title":"Models","text":"<ul> <li>MedAlpaca</li> <li>BloomBergGPT</li> <li>LexGPT</li> </ul>","tags":["ML","paper"]},{"location":"papers/ADAPTING%20LARGE%20LANGUAGE%20MODELS%20VIA%20READING%20COMPREHENSION/#resources","title":"Resources","text":"<p>Published as a conference paper at ICLR 2024 ,  ADAPTING LARGE LANGUAGE MODELS VIA READING COMPREHENSION Daixuan Cheng, Shaohan Huang\u2217 &amp; Furu Wei Microsoft Research https://huggingface.co/AdaptLLM</p>","tags":["ML","paper"]}]}